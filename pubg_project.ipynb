{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubhanshu1902/PUBG-ML-project/blob/main/pubg_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH9CGHkX57rj"
      },
      "source": [
        "# PUBG Project\n",
        "We have the dataset of different stats of players and we have to predict the rank of the player in the game.\n",
        "\n",
        "Team Name:- PUBG Specialist\n",
        "\n",
        "Team members:-\n",
        "- Shubhanshu Agrawal(IMT2020078)\n",
        "- Pratham Dandale(IMT2020038)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFjWYAmf0l2k"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB01G6ZT7vaD"
      },
      "source": [
        "Importing required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k88kjsgGyU6t"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nwUz4xI8JCK"
      },
      "source": [
        "Importing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVLZsDLRyU6y"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"./drive/MyDrive/PUbG/train_up.csv\")\n",
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4vLF7IuyU6z"
      },
      "outputs": [],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFPKMGnryU6z"
      },
      "source": [
        "# Pre-Processing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XROED9jJyU61"
      },
      "source": [
        "### Dealing with missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1lT1Lk5yU61"
      },
      "source": [
        "Calculating the missing values in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWaZvI3vyU62"
      },
      "outputs": [],
      "source": [
        "train_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfRmnVzSyU62"
      },
      "source": [
        "There only 1 missing value in winPlacePerc. \n",
        "\n",
        "Checking the row with missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZeZCJxlyU63"
      },
      "outputs": [],
      "source": [
        "train_df.loc[train_df['winPlacePerc'].isna(),:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jKYhZ5PyU64"
      },
      "source": [
        "Droping the row with missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk4718tfyU65"
      },
      "outputs": [],
      "source": [
        "train_df.drop(axis=\"rows\", labels=train_df.index[train_df[\"winPlacePerc\"].isna()], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hOW9O_NyU65"
      },
      "outputs": [],
      "source": [
        "train_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83rR6KR9yU66"
      },
      "source": [
        "### Dealing the duplicated rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JVzG91MyU66"
      },
      "source": [
        "Checking number of duplicated rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_v27zrpyU66"
      },
      "outputs": [],
      "source": [
        "train_df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJHcURuryU67"
      },
      "source": [
        "There are no duplicated rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WazfOWYyU67"
      },
      "source": [
        "### Label Encoding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0RiRZGXyU67"
      },
      "source": [
        "There is only 1 column which has categorical data,i.e., matchType. We will do label encoding in this column.\n",
        "\n",
        "GroupID, MatchID and Id have object type. So we can label encode them to make them integer type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lrbh6p6xyU68"
      },
      "outputs": [],
      "source": [
        "labelEncoder = LabelEncoder()\n",
        "train_copy = train_df.copy()\n",
        "encoded = labelEncoder.fit_transform(train_copy[\"matchType\"])\n",
        "train_copy[\"matchType\"].unique(),np.unique(encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x41sAXZmyU68"
      },
      "outputs": [],
      "source": [
        "train_copy[\"matchType\"] = encoded\n",
        "train_copy.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd_f26pzyU69"
      },
      "outputs": [],
      "source": [
        "train_copy[\"Id\"] = labelEncoder.fit_transform(train_copy[\"Id\"])\n",
        "train_copy[\"matchId\"] = labelEncoder.fit_transform(train_copy[\"matchId\"])\n",
        "train_copy[\"groupId\"] = labelEncoder.fit_transform(train_copy[\"groupId\"])\n",
        "\n",
        "train_df['Id'] = train_copy['Id']\n",
        "train_df['matchId'] = train_copy['matchId']\n",
        "train_df['groupId'] = train_copy['groupId']\n",
        "\n",
        "train_copy.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZwc1fmA8v7p"
      },
      "source": [
        "### Removing related columns\n",
        "\n",
        "We will make the heatmap of all the columns and check if they have corelation more than 0.8 or less than -0.8, we will remove them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlql9IajyU6-"
      },
      "outputs": [],
      "source": [
        "f,ax = plt.subplots(figsize=(15, 15))\n",
        "sns.heatmap(train_copy.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el1bl0QV9tq_"
      },
      "source": [
        "Relations:-\n",
        "- killPlace and killStreaks : -0.8\n",
        "- killPoints and rankPoints : -1.0\n",
        "- killPoints and winPoints : 1.0\n",
        "- maxPlace and numGroups : 1.0\n",
        "- rankPoints and winPoints : -1.0\n",
        "\n",
        "Removing killStreaks, rankPoints, killPoints, maxPlace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqXdE7TN4Uz-"
      },
      "outputs": [],
      "source": [
        "train_copy.drop(columns={\"killStreaks\",\"rankPoints\",\"killPoints\",\"maxPlace\"},axis=1,inplace=True)\n",
        "f,ax = plt.subplots(figsize=(15, 15))\n",
        "sns.heatmap(train_copy.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6JBLH_zyU6_"
      },
      "source": [
        "### Removing Outliers\n",
        "\n",
        "Removing outliers from every columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_L2ci_9yU6_"
      },
      "outputs": [],
      "source": [
        "class OutlierRemoval: \n",
        "    def __init__(self, lower_quartile, upper_quartile):\n",
        "        self.lower_whisker = lower_quartile - 1.5*(upper_quartile - lower_quartile)\n",
        "        self.upper_whisker = upper_quartile + 1.5*(upper_quartile - lower_quartile)\n",
        "    def removeOutlier(self, x):\n",
        "        return (x if x <= self.upper_whisker and x >= self.lower_whisker else (self.lower_whisker if x < self.lower_whisker else (self.upper_whisker)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6B0-jqbF3X_"
      },
      "source": [
        "Box plot for all the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBF7HRXtyU7A"
      },
      "outputs": [],
      "source": [
        "for i in list(train_copy.columns):\n",
        "    j=train_copy[i]\n",
        "    sns.boxplot(x=j)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDSIw3QA1Oa7"
      },
      "outputs": [],
      "source": [
        "train_copy.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwAsV9nHF9H1"
      },
      "source": [
        "As we can see some columns liske assist, revives, etc have numerical values, removing outliers will be not beneficial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc_7_zkr2gIj"
      },
      "outputs": [],
      "source": [
        "outliers = ['boosts', 'damageDealt', 'DBNOs',\n",
        "       'heals', 'killPlace', 'longestKill', 'matchDuration', 'matchType','numGroups', 'rideDistance',\n",
        "        'walkDistance', 'weaponsAcquired', 'winPoints']\n",
        "\n",
        "\n",
        "for i in list(outliers):\n",
        "    j=train_copy[i]\n",
        "    OutlierRemObj = OutlierRemoval(j.quantile(0.25),j.quantile(0.75))\n",
        "    remOut = j.apply(OutlierRemObj.removeOutlier)\n",
        "    sns.boxplot(x=remOut)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTlmY94GCNJc"
      },
      "source": [
        "### Min max Normalization \n",
        "\n",
        "Formula:- \n",
        "$$x_i = \\frac{x_i-min}{max-min}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAeFr_F5CMRs"
      },
      "outputs": [],
      "source": [
        "train = train_copy.drop(columns={\"Id\",\"matchId\",\"groupId\"})\n",
        "train = (train - train.min())/(train.max() - train.min())\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtJ9awbzE22-"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmjwpzzaL9R5"
      },
      "source": [
        "Checking number of matches in each category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlWNaSU99Ok-"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(1,2,figsize = (10,4))\n",
        "\n",
        "train_df.groupby(\"matchId\")[\"matchType\"].first().value_counts().plot.bar(ax=ax[0])\n",
        "\n",
        "seperator = lambda i: 'duo' if ('duo' in i) or ('crash' in i) else 'solo' if ('solo' in i) else 'squad' \n",
        "train_df['matchType'] = train_df['matchType'].apply(seperator)\n",
        "\n",
        "train_df.groupby(\"matchId\")[\"matchType\"].first().value_counts().plot.bar(ax=ax[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XX8H0qIOR89"
      },
      "outputs": [],
      "source": [
        "train[\"matchType\"] = labelEncoder.fit_transform(train_df[\"matchType\"])\n",
        "train[\"matchType\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxS2U_8Wc-kY"
      },
      "source": [
        "We will now explore the relations of different parameters on win position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj4px-BbZ45B"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x=\"winPlacePerc\", y=\"kills\", data=train_df, height=10, ratio=3, color=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOoe8Ay0dV9z"
      },
      "source": [
        "- We can see most kills are scattered between 0-10\n",
        "- Some people with more kills have less position in match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g24HTTIUdONv"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x=\"winPlacePerc\", y=\"assists\", data=train_df, height=10, ratio=3, color=\"b\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRSzzbKnnHCC"
      },
      "source": [
        "- Most assists scattered between 0-5\n",
        "- Some people with more kills have less position in match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV63Kms2gNJo"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x=\"winPlacePerc\", y=\"walkDistance\", data=train_df, height=10, ratio=3, color=\"r\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVnoGikdnR0A"
      },
      "source": [
        "- High rank people have travelled more than low rank people"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_csv(model,name):\n",
        "    test_df = pd.read_csv(\"./drive/MyDrive/PUbG/test_up.csv\")\n",
        "    answer = test_df[\"Id\"]\n",
        "\n",
        "    test_df.drop(columns={\"killStreaks\",\"rankPoints\",\"killPoints\",\"maxPlace\"},axis=1,inplace=True)\n",
        "    test_df = test_df.drop(columns={\"Id\",\"matchId\",\"groupId\"})\n",
        "    \n",
        "    seperator = lambda i: 'duo' if ('duo' in i) or ('crash' in i) else 'solo' if ('solo' in i) else 'squad' \n",
        "    test_df['matchType'] = test_df['matchType'].apply(seperator)\n",
        "    test_df[\"matchType\"] = labelEncoder.fit_transform(test_df[\"matchType\"])\n",
        "    \n",
        "    test_df = (test_df - test_df.min())/(test_df.max() - test_df.min())\n",
        "    prediction = model.predict(test_df)\n",
        "    \n",
        "    test_df = test_df.drop(columns = test_df.columns,axis=1)\n",
        "    test_df[\"Id\"] = answer\n",
        "    test_df[\"winPlacePerc\"] = prediction\n",
        "    \n",
        "    test_df.to_csv('./drive/MyDrive/PUbG/'+name,index=False)"
      ],
      "metadata": {
        "id": "BJdvsWouZIII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def fit_model(model,X,Y,output_csv):\n",
        "    train_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=0.1)\n",
        "    model.fit(train_x,train_y)\n",
        "    predict_y = model.predict(test_x)\n",
        "    mse = mean_squared_error(test_y, predict_y) \n",
        "    print(\"MEAN SQUARED ERROR :-\", mse)\n",
        "    fit_csv(model,output_csv)\n",
        "    print(\"CSV created in drive\")"
      ],
      "metadata": {
        "id": "0vAKigV6Z52g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train[\"Id\"] = train_df[\"Id\"]\n",
        "\n",
        "\n",
        "x = train.drop(columns=\"winPlacePerc\",axis=1)\n",
        "y = train[\"winPlacePerc\"]"
      ],
      "metadata": {
        "id": "h95USUD1dVX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Model"
      ],
      "metadata": {
        "id": "ll2DVW8pdqvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "\n",
        "decision_tree = tree.DecisionTreeRegressor()\n",
        "fit_model(decision_tree,x,y,\"decision_tree.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH7mYRiYdjse",
        "outputId": "39a6a5d1-dfea-47d3-a775-7e49642dee28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SQUARED ERROR :- 0.013886201662685713\n",
            "CSV created in drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Regression model"
      ],
      "metadata": {
        "id": "fOTW6Pp-d9e-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "random_forest = RandomForestRegressor(max_depth=6, random_state=2)\n",
        "fit_model(random_forest,x,y,\"random_forest.csv\")"
      ],
      "metadata": {
        "id": "K24U9Qftd0ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting Regression"
      ],
      "metadata": {
        "id": "Nq3ibJQDeZQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": 500,\n",
        "    \"max_depth\": 4,\n",
        "    \"min_samples_split\": 5,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"loss\": \"squared_error\",\n",
        "}\n",
        "\n",
        "gbr = ensemble.GradientBoostingRegressor(**params)\n",
        "fit_model(gbr,x,y,\"gradient_boosting_regressor.csv\")"
      ],
      "metadata": {
        "id": "MeJg7SFVeYS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Elastic Net Regression"
      ],
      "metadata": {
        "id": "z_DdC4CHtwtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "elasticNet = ElasticNet(random_state=0)\n",
        "fit_model(elasticNet,x,y,\"elastic_net.csv\") "
      ],
      "metadata": {
        "id": "-fuJlBtshBYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Gradient Descent Regression"
      ],
      "metadata": {
        "id": "FFTfDwjkuH_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sgdregressor = reg = make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000000, tol=1e-3))\n",
        "fit_model(sgdregressor,x,y,\"sgdRegressor.csv\")"
      ],
      "metadata": {
        "id": "aH-fLg0LuKx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine"
      ],
      "metadata": {
        "id": "a8ge3pjYuiVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "svm = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
        "fit_model(sgdregressor,x,y,\"svm,csv\")"
      ],
      "metadata": {
        "id": "17hVz8yJu15M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "ZOHyZ-JLvQD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "linReg = LinearRegression()\n",
        "fit_model(linReg,x,y,\"linear_reg.csv\")"
      ],
      "metadata": {
        "id": "SsU69suVvQss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XG Boost Regressor"
      ],
      "metadata": {
        "id": "8GE6f9Owv3F4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost"
      ],
      "metadata": {
        "id": "AjrvLjtPv5Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\":1000, \n",
        "    \"max_depth\":7, \n",
        "    \"eta\":0.1, \n",
        "    \"subsample\":0.7, \n",
        "    \"colsample_bytree\":0.8,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"loss\": \"squared_error\",\n",
        "}\n",
        "\n",
        "xgBoost = XGBRegressor(**params) \n",
        "fit_model(xgBoost,x,y,\"xgboost.csv\")"
      ],
      "metadata": {
        "id": "kCm7Z2b_v9uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SwDNIhUZ1KbL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "83rR6KR9yU66",
        "PZwc1fmA8v7p",
        "qTlmY94GCNJc"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}